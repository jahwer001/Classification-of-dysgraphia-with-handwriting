{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da6453f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: pillow in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (11.2.1)\n",
      "Requirement already satisfied: textblob in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: pyspellchecker in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (0.8.2)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from pytesseract) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.4)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (4.64.1)\n",
      "Requirement already satisfied: click in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (2022.7.9)\n",
      "Requirement already satisfied: joblib in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from packaging>=21.3->pytesseract) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from click->nltk>=3.9->textblob) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract opencv-python pillow textblob pyspellchecker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecbf0fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from spellchecker import SpellChecker\n",
    "from textblob import TextBlob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad99ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afcab778",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = SpellChecker()\n",
    "\n",
    "def extract_text(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    return pytesseract.image_to_string(image)\n",
    "\n",
    "def spelling_accuracy(text):\n",
    "    words = text.split()\n",
    "    if not words:\n",
    "        return 0\n",
    "    misspelled = spell.unknown(words)\n",
    "    accuracy = 1 - len(misspelled) / len(words)\n",
    "    return round(accuracy, 3)\n",
    "\n",
    "def phonetic_accuracy(text):\n",
    "    words = text.split()\n",
    "    if not words:\n",
    "        return 0\n",
    "    misspelled = spell.unknown(words)\n",
    "    phonetically_correct = sum([1 for word in misspelled if spell.correction(word) and spell.correction(word)[0] == word[0]])\n",
    "    if not misspelled:\n",
    "        return 1.0\n",
    "    return round(phonetically_correct / len(misspelled), 3)\n",
    "\n",
    "def dummy_alignment_score(image_path):\n",
    "    # Placeholder: Assume all images are well-aligned for now\n",
    "    return 1.0\n",
    "\n",
    "def dummy_correction_rate(image_path):\n",
    "    # Placeholder: You can later use OpenCV to detect overwritten text\n",
    "    return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b2653f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(folder_path, label):\n",
    "    data = []\n",
    "    for filename in tqdm(os.listdir(folder_path)):\n",
    "        if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            text = extract_text(image_path)\n",
    "            features = {\n",
    "                'image_id': filename,\n",
    "                'spelling_accuracy': spelling_accuracy(text),\n",
    "                'phonetic_accuracy': phonetic_accuracy(text),\n",
    "                'alignment_score': dummy_alignment_score(image_path),\n",
    "                'correction_rate': dummy_correction_rate(image_path),\n",
    "                'label': label\n",
    "            }\n",
    "            data.append(features)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfe92083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [01:44<00:00,  2.08s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [04:34<00:00,  5.48s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>spelling_accuracy</th>\n",
       "      <th>phonetic_accuracy</th>\n",
       "      <th>alignment_score</th>\n",
       "      <th>correction_rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.jpg</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.jpg</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.jpg</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  spelling_accuracy  phonetic_accuracy  alignment_score  \\\n",
       "0    1.jpg              0.000              0.000              1.0   \n",
       "1   10.jpg              0.579              0.625              1.0   \n",
       "2   11.jpg              0.545              0.467              1.0   \n",
       "3   12.jpg              0.556              0.625              1.0   \n",
       "4   13.jpg              0.568              0.438              1.0   \n",
       "\n",
       "   correction_rate  label  \n",
       "0              0.0      1  \n",
       "1              0.0      1  \n",
       "2              0.0      1  \n",
       "3              0.0      1  \n",
       "4              0.0      1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dyslexic_folder = r'C:\\Users\\Dyslexia_Detection-main\\Dyslexia_data\\dyslexic'\n",
    "non_dyslexic_folder = r'C:\\Users\\Dyslexia_Detection-main\\Dyslexia_data\\non_dyslexic'\n",
    "\n",
    "dyslexic_data = process_dataset(dyslexic_folder, label=1)\n",
    "non_dyslexic_data = process_dataset(non_dyslexic_folder, label=0)\n",
    "\n",
    "full_data = dyslexic_data + non_dyslexic_data\n",
    "df = pd.DataFrame(full_data)\n",
    "df.to_csv('dyslexia_features.csv', index=False)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98113356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>spelling_accuracy</th>\n",
       "      <th>phonetic_accuracy</th>\n",
       "      <th>alignment_score</th>\n",
       "      <th>correction_rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.jpg</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.jpg</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.jpg</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>50.jpg</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.688</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6.jpg</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.536</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7.jpg</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.737</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>8.jpg</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>9.jpg</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.471</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  spelling_accuracy  phonetic_accuracy  alignment_score  \\\n",
       "0     1.jpg              0.000              0.000              1.0   \n",
       "1    10.jpg              0.579              0.625              1.0   \n",
       "2    11.jpg              0.545              0.467              1.0   \n",
       "3    12.jpg              0.556              0.625              1.0   \n",
       "4    13.jpg              0.568              0.438              1.0   \n",
       "..      ...                ...                ...              ...   \n",
       "95   50.jpg              0.448              0.688              1.0   \n",
       "96    6.jpg              0.606              0.536              1.0   \n",
       "97    7.jpg              0.732              0.737              1.0   \n",
       "98    8.jpg              0.582              0.696              1.0   \n",
       "99    9.jpg              0.712              0.471              1.0   \n",
       "\n",
       "    correction_rate  label  \n",
       "0               0.0      1  \n",
       "1               0.0      1  \n",
       "2               0.0      1  \n",
       "3               0.0      1  \n",
       "4               0.0      1  \n",
       "..              ...    ...  \n",
       "95              0.0      0  \n",
       "96              0.0      0  \n",
       "97              0.0      0  \n",
       "98              0.0      0  \n",
       "99              0.0      0  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35032893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (0.22.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from torch) (2022.7.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48ddbf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4f1145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DyslexiaHybridDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_folder, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        image_path = os.path.join(self.image_folder, row['image_id'])\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Extract linguistic features as tensor\n",
    "        linguistic_feats = torch.tensor([\n",
    "            row['spelling_accuracy'],\n",
    "            row['phonetic_accuracy'],\n",
    "            row['alignment_score'],\n",
    "            row['correction_rate']\n",
    "        ], dtype=torch.float32)\n",
    "\n",
    "        label = torch.tensor(row['label'], dtype=torch.long)\n",
    "\n",
    "        return image, linguistic_feats, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ec1a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "dataset = DyslexiaHybridDataset(\n",
    "    csv_file='dyslexia_features.csv',\n",
    "    image_folder=r'C:\\Users\\Dyslexia_Detection-main\\Dyslexia_data\\all',  # combine dyslexic & non_dyslexic in one folder\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c2349c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 224, 224])\n",
      "torch.Size([16, 4])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "for img, text_feats, label in dataloader:\n",
    "    print(img.shape)        # (B, 3, 224, 224)\n",
    "    print(text_feats.shape) # (B, 4)\n",
    "    print(label.shape)      # (B,)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92682066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class HybridDyslexiaModel(nn.Module):\n",
    "    def __init__(self, linguistic_input_dim=4, num_classes=2):\n",
    "        super(HybridDyslexiaModel, self).__init__()\n",
    "\n",
    "        # 1. CNN Branch\n",
    "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        self.cnn_backbone = mobilenet.features  # remove classifier\n",
    "        self.cnn_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.cnn_output_dim = 1280  # output from MobileNetV2\n",
    "\n",
    "        # 2. Linguistic Branch\n",
    "        self.linguistic_net = nn.Sequential(\n",
    "            nn.Linear(linguistic_input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # 3. Fusion + Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.cnn_output_dim + 64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, linguistic_feats):\n",
    "        # CNN branch\n",
    "        x_img = self.cnn_backbone(image)\n",
    "        x_img = self.cnn_pool(x_img)\n",
    "        x_img = x_img.view(x_img.size(0), -1)\n",
    "\n",
    "        # Linguistic branch\n",
    "        x_text = self.linguistic_net(linguistic_feats)\n",
    "\n",
    "        # Concatenate both\n",
    "        x = torch.cat((x_img, x_text), dim=1)\n",
    "        out = self.classifier(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b15ec2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rjabj\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rjabj\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to C:\\Users\\rjabj/.cache\\torch\\hub\\checkpoints\\mobilenet_v2-b0353104.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 13.6M/13.6M [00:08<00:00, 1.65MB/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridDyslexiaModel().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a0dc868",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# 80% train, 20% validation\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = total_size - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efa711c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "222dca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, val_loss = 0.0, 0.0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        for images, text_feats, labels in train_loader:\n",
    "            images, text_feats, labels = images.to(device), text_feats.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, text_feats)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, text_feats, labels in val_loader:\n",
    "                images, text_feats, labels = images.to(device), text_feats.to(device), labels.to(device)\n",
    "                outputs = model(images, text_feats)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f} \"\n",
    "              f\"Val Acc: {val_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed81d77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Train Loss: 0.7453 Val Loss: 0.7052 Val Acc: 40.00%\n",
      "Epoch [2/10] Train Loss: 0.6722 Val Loss: 0.6880 Val Acc: 60.00%\n",
      "Epoch [3/10] Train Loss: 0.6650 Val Loss: 0.7057 Val Acc: 35.00%\n",
      "Epoch [4/10] Train Loss: 0.6697 Val Loss: 0.7153 Val Acc: 30.00%\n",
      "Epoch [5/10] Train Loss: 0.6272 Val Loss: 0.7144 Val Acc: 40.00%\n",
      "Epoch [6/10] Train Loss: 0.6357 Val Loss: 0.7628 Val Acc: 30.00%\n",
      "Epoch [7/10] Train Loss: 0.6244 Val Loss: 0.8550 Val Acc: 25.00%\n",
      "Epoch [8/10] Train Loss: 0.6310 Val Loss: 0.9983 Val Acc: 10.00%\n",
      "Epoch [9/10] Train Loss: 0.6521 Val Loss: 1.1484 Val Acc: 10.00%\n",
      "Epoch [10/10] Train Loss: 0.6145 Val Loss: 1.1823 Val Acc: 10.00%\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99f8e34",
   "metadata": {},
   "source": [
    "# methode 2 only cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59225a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(r'C:\\Users\\train', transform=transform)\n",
    "val_data = datasets.ImageFolder(r'C:\\Users\\val', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c7ae790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.backbone = models.mobilenet_v2(pretrained=True)\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.backbone.last_channel, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "model = CNNClassifier().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "282c6145",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f804a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, val_loss = 0.0, 0.0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f} \"\n",
    "              f\"Val Acc: {val_accuracy:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0dfc189a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Train Loss: 0.0347 Val Loss: 0.0129 Val Acc: 100.00%\n",
      "Epoch [2/10] Train Loss: 0.0097 Val Loss: 0.0192 Val Acc: 100.00%\n",
      "Epoch [3/10] Train Loss: 0.0130 Val Loss: 0.0301 Val Acc: 95.00%\n",
      "Epoch [4/10] Train Loss: 0.0029 Val Loss: 0.0119 Val Acc: 100.00%\n",
      "Epoch [5/10] Train Loss: 0.0081 Val Loss: 0.0233 Val Acc: 95.00%\n",
      "Epoch [6/10] Train Loss: 0.0018 Val Loss: 0.0076 Val Acc: 100.00%\n",
      "Epoch [7/10] Train Loss: 0.0026 Val Loss: 0.0117 Val Acc: 100.00%\n",
      "Epoch [8/10] Train Loss: 0.0145 Val Loss: 0.0011 Val Acc: 100.00%\n",
      "Epoch [9/10] Train Loss: 0.0009 Val Loss: 0.0006 Val Acc: 100.00%\n",
      "Epoch [10/10] Train Loss: 0.0018 Val Loss: 0.0017 Val Acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1d9c3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  0]\n",
      " [ 0 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "non_dyslexic       1.00      1.00      1.00        10\n",
      "    dyslexic       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Evaluate model\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Show results\n",
    "print(confusion_matrix(all_labels, all_preds))\n",
    "print(classification_report(all_labels, all_preds, target_names=['non_dyslexic', 'dyslexic']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9131c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "770281bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a71812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01f9a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path, model, transform, class_names=['non_dyslexic', 'dyslexic']):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        probabilities = F.softmax(output, dim=1)\n",
    "        confidence, predicted_class = torch.max(probabilities, 1)\n",
    "        prediction = class_names[predicted_class.item()]\n",
    "\n",
    "    print(f\"Prediction: {prediction} (Confidence: {confidence.item()*100:.2f}%)\")\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a713764f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: non_dyslexic (Confidence: 99.93%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'non_dyslexic'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_image(r\"C:\\Users\\test_image_path.jpg\", model, transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941a66f7",
   "metadata": {},
   "source": [
    "# 3rd trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a25e61ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f23f8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rjabj\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rjabj\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load ResNet18 and remove the classification layer\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet = nn.Sequential(*list(resnet.children())[:-1])  # remove final FC\n",
    "resnet.to(device)\n",
    "resnet.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "892d4f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet stats\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2179e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_folder(folder_path, label):\n",
    "    features = []\n",
    "    for filename in tqdm(os.listdir(folder_path)):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                image = Image.open(image_path).convert('RGB')\n",
    "                img_tensor = transform(image).unsqueeze(0).to(device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    output = resnet(img_tensor).squeeze().cpu().numpy()\n",
    "                \n",
    "                features.append({\n",
    "                    'image_id': filename,\n",
    "                    'features': output,\n",
    "                    'label': label\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error with {filename}: {e}\")\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cef77a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 30.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 34.98it/s]\n"
     ]
    }
   ],
   "source": [
    "dyslexic_folder = r'C:\\Users\\rjabj\\Desktop\\projects\\au cour\\Projet Fatma\\Dyslexia_Detection-main\\Dyslexia_data\\dyslexic'\n",
    "non_dyslexic_folder = r'C:\\Users\\rjabj\\Desktop\\projects\\au cour\\Projet Fatma\\Dyslexia_Detection-main\\Dyslexia_data\\non_dyslexic'\n",
    "\n",
    "dyslexic_features = extract_features_from_folder(dyslexic_folder, label=1)\n",
    "non_dyslexic_features = extract_features_from_folder(non_dyslexic_folder, label=0)\n",
    "\n",
    "all_features = dyslexic_features + non_dyslexic_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22cefae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "rows = []\n",
    "for item in all_features:\n",
    "    row = {'image_id': item['image_id'], 'label': item['label']}\n",
    "    # Add CNN features as individual columns\n",
    "    for i, val in enumerate(item['features']):\n",
    "        row[f'cnn_feat_{i}'] = val\n",
    "    rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(\"cnn_features_only.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59b55801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>cnn_feat_0</th>\n",
       "      <th>cnn_feat_1</th>\n",
       "      <th>cnn_feat_2</th>\n",
       "      <th>cnn_feat_3</th>\n",
       "      <th>cnn_feat_4</th>\n",
       "      <th>cnn_feat_5</th>\n",
       "      <th>cnn_feat_6</th>\n",
       "      <th>cnn_feat_7</th>\n",
       "      <th>...</th>\n",
       "      <th>cnn_feat_502</th>\n",
       "      <th>cnn_feat_503</th>\n",
       "      <th>cnn_feat_504</th>\n",
       "      <th>cnn_feat_505</th>\n",
       "      <th>cnn_feat_506</th>\n",
       "      <th>cnn_feat_507</th>\n",
       "      <th>cnn_feat_508</th>\n",
       "      <th>cnn_feat_509</th>\n",
       "      <th>cnn_feat_510</th>\n",
       "      <th>cnn_feat_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.642288</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.107192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031598</td>\n",
       "      <td>1.115427</td>\n",
       "      <td>0.416744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.599575</td>\n",
       "      <td>0.260037</td>\n",
       "      <td>0.007689</td>\n",
       "      <td>0.945368</td>\n",
       "      <td>0.422083</td>\n",
       "      <td>0.051652</td>\n",
       "      <td>0.165086</td>\n",
       "      <td>0.115031</td>\n",
       "      <td>0.013628</td>\n",
       "      <td>0.342411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>0.168988</td>\n",
       "      <td>0.153275</td>\n",
       "      <td>0.457574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447910</td>\n",
       "      <td>0.247509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.367099</td>\n",
       "      <td>0.170162</td>\n",
       "      <td>0.219995</td>\n",
       "      <td>0.130606</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.002865</td>\n",
       "      <td>0.242844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015517</td>\n",
       "      <td>0.353313</td>\n",
       "      <td>0.382393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111827</td>\n",
       "      <td>0.129960</td>\n",
       "      <td>1.281773</td>\n",
       "      <td>0.756605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251292</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109606</td>\n",
       "      <td>0.463858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144457</td>\n",
       "      <td>0.241148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.481109</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>0.631381</td>\n",
       "      <td>0.298817</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039086</td>\n",
       "      <td>0.986352</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241583</td>\n",
       "      <td>0.417748</td>\n",
       "      <td>0.014736</td>\n",
       "      <td>0.970470</td>\n",
       "      <td>0.234780</td>\n",
       "      <td>0.481547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.627965</td>\n",
       "      <td>0.404462</td>\n",
       "      <td>0.120683</td>\n",
       "      <td>0.189503</td>\n",
       "      <td>0.028826</td>\n",
       "      <td>0.660616</td>\n",
       "      <td>0.970743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109243</td>\n",
       "      <td>0.045739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.632476</td>\n",
       "      <td>0.186619</td>\n",
       "      <td>0.049234</td>\n",
       "      <td>0.027364</td>\n",
       "      <td>0.492153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.530912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>50.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027615</td>\n",
       "      <td>0.049322</td>\n",
       "      <td>0.207518</td>\n",
       "      <td>0.469478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430745</td>\n",
       "      <td>0.175257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392176</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.332881</td>\n",
       "      <td>0.589594</td>\n",
       "      <td>0.129699</td>\n",
       "      <td>0.101512</td>\n",
       "      <td>0.123570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019854</td>\n",
       "      <td>0.167091</td>\n",
       "      <td>0.009731</td>\n",
       "      <td>0.760850</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.811464</td>\n",
       "      <td>0.842773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533118</td>\n",
       "      <td>0.013945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576123</td>\n",
       "      <td>0.386453</td>\n",
       "      <td>0.115167</td>\n",
       "      <td>0.065269</td>\n",
       "      <td>0.626676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012485</td>\n",
       "      <td>0.033377</td>\n",
       "      <td>0.117502</td>\n",
       "      <td>0.565181</td>\n",
       "      <td>0.029468</td>\n",
       "      <td>1.186909</td>\n",
       "      <td>1.608112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866599</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>0.018752</td>\n",
       "      <td>0.383488</td>\n",
       "      <td>0.992136</td>\n",
       "      <td>0.035201</td>\n",
       "      <td>0.079573</td>\n",
       "      <td>0.620282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>8.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015382</td>\n",
       "      <td>0.041938</td>\n",
       "      <td>0.267882</td>\n",
       "      <td>0.431906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.670172</td>\n",
       "      <td>0.766894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248161</td>\n",
       "      <td>0.004550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.527290</td>\n",
       "      <td>0.393177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086598</td>\n",
       "      <td>0.016604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>9.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034008</td>\n",
       "      <td>0.128671</td>\n",
       "      <td>0.069263</td>\n",
       "      <td>0.768720</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.747760</td>\n",
       "      <td>0.753055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218405</td>\n",
       "      <td>0.038124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.647218</td>\n",
       "      <td>0.348779</td>\n",
       "      <td>0.006385</td>\n",
       "      <td>0.075631</td>\n",
       "      <td>0.172105</td>\n",
       "      <td>0.006464</td>\n",
       "      <td>0.111514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 514 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  label  cnn_feat_0  cnn_feat_1  cnn_feat_2  cnn_feat_3  \\\n",
       "0     1.jpg      1    0.000341    0.642288    0.000963    0.107192   \n",
       "1    10.jpg      1    0.000000    0.002962    0.168988    0.153275   \n",
       "2    11.jpg      1    0.015517    0.353313    0.382393    0.000000   \n",
       "3    12.jpg      1    0.481109    1.060660    0.631381    0.298817   \n",
       "4    13.jpg      1    0.000000    0.627965    0.404462    0.120683   \n",
       "..      ...    ...         ...         ...         ...         ...   \n",
       "95   50.jpg      0    0.000000    0.027615    0.049322    0.207518   \n",
       "96    6.jpg      0    0.000000    0.019854    0.167091    0.009731   \n",
       "97    7.jpg      0    0.000000    0.012485    0.033377    0.117502   \n",
       "98    8.jpg      0    0.000000    0.015382    0.041938    0.267882   \n",
       "99    9.jpg      0    0.000000    0.034008    0.128671    0.069263   \n",
       "\n",
       "    cnn_feat_4  cnn_feat_5  cnn_feat_6  cnn_feat_7  ...  cnn_feat_502  \\\n",
       "0     0.000000    0.031598    1.115427    0.416744  ...      0.599575   \n",
       "1     0.457574    0.000000    0.447910    0.247509  ...      0.009383   \n",
       "2     0.111827    0.129960    1.281773    0.756605  ...      0.251292   \n",
       "3     0.000000    0.039086    0.986352    0.025400  ...      0.241583   \n",
       "4     0.189503    0.028826    0.660616    0.970743  ...      0.109243   \n",
       "..         ...         ...         ...         ...  ...           ...   \n",
       "95    0.469478    0.000000    0.430745    0.175257  ...      0.392176   \n",
       "96    0.760850    0.000536    0.811464    0.842773  ...      0.533118   \n",
       "97    0.565181    0.029468    1.186909    1.608112  ...      0.866599   \n",
       "98    0.431906    0.000000    0.670172    0.766894  ...      0.248161   \n",
       "99    0.768720    0.000780    0.747760    0.753055  ...      0.218405   \n",
       "\n",
       "    cnn_feat_503  cnn_feat_504  cnn_feat_505  cnn_feat_506  cnn_feat_507  \\\n",
       "0       0.260037      0.007689      0.945368      0.422083      0.051652   \n",
       "1       0.000000      0.000000      0.367099      0.170162      0.219995   \n",
       "2       0.001687      0.000000      0.109606      0.463858      0.000000   \n",
       "3       0.417748      0.014736      0.970470      0.234780      0.481547   \n",
       "4       0.045739      0.000000      0.632476      0.186619      0.049234   \n",
       "..           ...           ...           ...           ...           ...   \n",
       "95      0.003169      0.000786      0.332881      0.589594      0.129699   \n",
       "96      0.013945      0.000000      0.576123      0.386453      0.115167   \n",
       "97      0.004125      0.018752      0.383488      0.992136      0.035201   \n",
       "98      0.004550      0.000000      0.527290      0.393177      0.000000   \n",
       "99      0.038124      0.000000      0.647218      0.348779      0.006385   \n",
       "\n",
       "    cnn_feat_508  cnn_feat_509  cnn_feat_510  cnn_feat_511  \n",
       "0       0.165086      0.115031      0.013628      0.342411  \n",
       "1       0.130606      0.004055      0.002865      0.242844  \n",
       "2       0.144457      0.241148      0.000000      0.030442  \n",
       "3       0.000000      0.012534      0.000000      0.053672  \n",
       "4       0.027364      0.492153      0.000000      0.530912  \n",
       "..           ...           ...           ...           ...  \n",
       "95      0.101512      0.123570      0.000000      0.034644  \n",
       "96      0.065269      0.626676      0.000000      0.084644  \n",
       "97      0.079573      0.620282      0.000000      0.123685  \n",
       "98      0.086598      0.016604      0.000000      0.195467  \n",
       "99      0.075631      0.172105      0.006464      0.111514  \n",
       "\n",
       "[100 rows x 514 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "026e74e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: language-tool-python in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (2.9.3)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from pytesseract) (11.2.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from pytesseract) (21.3)\n",
      "Requirement already satisfied: requests in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from language-tool-python) (2.28.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from language-tool-python) (5.9.0)\n",
      "Requirement already satisfied: toml in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from language-tool-python) (0.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from language-tool-python) (4.64.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from packaging>=21.3->pytesseract) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from requests->language-tool-python) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from requests->language-tool-python) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from requests->language-tool-python) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from requests->language-tool-python) (2022.9.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\rjabj\\anaconda3\\lib\\site-packages (from tqdm->language-tool-python) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytesseract language-tool-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15922518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import language_tool_python\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a0e9c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb761b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    return pytesseract.image_to_string(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "357ec73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "def grammar_error_count(text):\n",
    "    matches = tool.check(text)\n",
    "    return len(matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eea84a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rjabj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def sentence_features(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentence_count = len(sentences)\n",
    "    avg_length = np.mean([len(s.split()) for s in sentences]) if sentences else 0\n",
    "    return sentence_count, avg_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98a8e659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_alignment_variance(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    _, binary = cv2.threshold(img, 180, 255, cv2.THRESH_BINARY_INV)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    x_starts = [cv2.boundingRect(c)[0] for c in contours if cv2.boundingRect(c)[2] > 50]\n",
    "    return np.var(x_starts) if x_starts else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e65d1bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_linguistic_features(image_path):\n",
    "    try:\n",
    "        text = extract_text(image_path)\n",
    "        grammar_errors = grammar_error_count(text)\n",
    "        sent_count, avg_sent_len = sentence_features(text)\n",
    "        alignment_var = line_alignment_variance(image_path)\n",
    "        \n",
    "        return {\n",
    "            'grammar_errors': grammar_errors,\n",
    "            'sentence_count': sent_count,\n",
    "            'avg_sentence_length': avg_sent_len,\n",
    "            'alignment_variance': alignment_var\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Failed for {image_path}: {e}\")\n",
    "        return {\n",
    "            'grammar_errors': 0,\n",
    "            'sentence_count': 0,\n",
    "            'avg_sentence_length': 0,\n",
    "            'alignment_variance': 0\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "059e64b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:53<00:00,  1.87it/s]\n"
     ]
    }
   ],
   "source": [
    "for item in tqdm(all_features):\n",
    "    img_path = os.path.join(dyslexic_folder if item['label'] == 1 else non_dyslexic_folder, item['image_id'])\n",
    "    linguistic = extract_linguistic_features(img_path)\n",
    "    item.update(linguistic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b1824e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for item in all_features:\n",
    "    row = {'image_id': item['image_id'], 'label': item['label']}\n",
    "    for i, val in enumerate(item['features']):\n",
    "        row[f'cnn_feat_{i}'] = val\n",
    "    row.update({\n",
    "        'grammar_errors': item['grammar_errors'],\n",
    "        'sentence_count': item['sentence_count'],\n",
    "        'avg_sentence_length': item['avg_sentence_length'],\n",
    "        'alignment_variance': item['alignment_variance']\n",
    "    })\n",
    "    rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(\"hybrid_features.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91ea57e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>cnn_feat_0</th>\n",
       "      <th>cnn_feat_1</th>\n",
       "      <th>cnn_feat_2</th>\n",
       "      <th>cnn_feat_3</th>\n",
       "      <th>cnn_feat_4</th>\n",
       "      <th>cnn_feat_5</th>\n",
       "      <th>cnn_feat_6</th>\n",
       "      <th>cnn_feat_7</th>\n",
       "      <th>...</th>\n",
       "      <th>cnn_feat_506</th>\n",
       "      <th>cnn_feat_507</th>\n",
       "      <th>cnn_feat_508</th>\n",
       "      <th>cnn_feat_509</th>\n",
       "      <th>cnn_feat_510</th>\n",
       "      <th>cnn_feat_511</th>\n",
       "      <th>grammar_errors</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>alignment_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.642288</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.107192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031598</td>\n",
       "      <td>1.115427</td>\n",
       "      <td>0.416744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422083</td>\n",
       "      <td>0.051652</td>\n",
       "      <td>0.165086</td>\n",
       "      <td>0.115031</td>\n",
       "      <td>0.013628</td>\n",
       "      <td>0.342411</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7.00</td>\n",
       "      <td>22973.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>0.168988</td>\n",
       "      <td>0.153275</td>\n",
       "      <td>0.457574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447910</td>\n",
       "      <td>0.247509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170162</td>\n",
       "      <td>0.219995</td>\n",
       "      <td>0.130606</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.002865</td>\n",
       "      <td>0.242844</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>38.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015517</td>\n",
       "      <td>0.353313</td>\n",
       "      <td>0.382393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111827</td>\n",
       "      <td>0.129960</td>\n",
       "      <td>1.281773</td>\n",
       "      <td>0.756605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144457</td>\n",
       "      <td>0.241148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.481109</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>0.631381</td>\n",
       "      <td>0.298817</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039086</td>\n",
       "      <td>0.986352</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234780</td>\n",
       "      <td>0.481547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053672</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>16.00</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.627965</td>\n",
       "      <td>0.404462</td>\n",
       "      <td>0.120683</td>\n",
       "      <td>0.189503</td>\n",
       "      <td>0.028826</td>\n",
       "      <td>0.660616</td>\n",
       "      <td>0.970743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186619</td>\n",
       "      <td>0.049234</td>\n",
       "      <td>0.027364</td>\n",
       "      <td>0.492153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.530912</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>37.00</td>\n",
       "      <td>168054.619172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>50.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027615</td>\n",
       "      <td>0.049322</td>\n",
       "      <td>0.207518</td>\n",
       "      <td>0.469478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430745</td>\n",
       "      <td>0.175257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589594</td>\n",
       "      <td>0.129699</td>\n",
       "      <td>0.101512</td>\n",
       "      <td>0.123570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034644</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>60.00</td>\n",
       "      <td>8266.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019854</td>\n",
       "      <td>0.167091</td>\n",
       "      <td>0.009731</td>\n",
       "      <td>0.760850</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.811464</td>\n",
       "      <td>0.842773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386453</td>\n",
       "      <td>0.115167</td>\n",
       "      <td>0.065269</td>\n",
       "      <td>0.626676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084644</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>71.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012485</td>\n",
       "      <td>0.033377</td>\n",
       "      <td>0.117502</td>\n",
       "      <td>0.565181</td>\n",
       "      <td>0.029468</td>\n",
       "      <td>1.186909</td>\n",
       "      <td>1.608112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992136</td>\n",
       "      <td>0.035201</td>\n",
       "      <td>0.079573</td>\n",
       "      <td>0.620282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123685</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>35.50</td>\n",
       "      <td>7396.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>8.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015382</td>\n",
       "      <td>0.041938</td>\n",
       "      <td>0.267882</td>\n",
       "      <td>0.431906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.670172</td>\n",
       "      <td>0.766894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086598</td>\n",
       "      <td>0.016604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195467</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>13.75</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>9.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034008</td>\n",
       "      <td>0.128671</td>\n",
       "      <td>0.069263</td>\n",
       "      <td>0.768720</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.747760</td>\n",
       "      <td>0.753055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348779</td>\n",
       "      <td>0.006385</td>\n",
       "      <td>0.075631</td>\n",
       "      <td>0.172105</td>\n",
       "      <td>0.006464</td>\n",
       "      <td>0.111514</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 518 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  label  cnn_feat_0  cnn_feat_1  cnn_feat_2  cnn_feat_3  \\\n",
       "0     1.jpg      1    0.000341    0.642288    0.000963    0.107192   \n",
       "1    10.jpg      1    0.000000    0.002962    0.168988    0.153275   \n",
       "2    11.jpg      1    0.015517    0.353313    0.382393    0.000000   \n",
       "3    12.jpg      1    0.481109    1.060660    0.631381    0.298817   \n",
       "4    13.jpg      1    0.000000    0.627965    0.404462    0.120683   \n",
       "..      ...    ...         ...         ...         ...         ...   \n",
       "95   50.jpg      0    0.000000    0.027615    0.049322    0.207518   \n",
       "96    6.jpg      0    0.000000    0.019854    0.167091    0.009731   \n",
       "97    7.jpg      0    0.000000    0.012485    0.033377    0.117502   \n",
       "98    8.jpg      0    0.000000    0.015382    0.041938    0.267882   \n",
       "99    9.jpg      0    0.000000    0.034008    0.128671    0.069263   \n",
       "\n",
       "    cnn_feat_4  cnn_feat_5  cnn_feat_6  cnn_feat_7  ...  cnn_feat_506  \\\n",
       "0     0.000000    0.031598    1.115427    0.416744  ...      0.422083   \n",
       "1     0.457574    0.000000    0.447910    0.247509  ...      0.170162   \n",
       "2     0.111827    0.129960    1.281773    0.756605  ...      0.463858   \n",
       "3     0.000000    0.039086    0.986352    0.025400  ...      0.234780   \n",
       "4     0.189503    0.028826    0.660616    0.970743  ...      0.186619   \n",
       "..         ...         ...         ...         ...  ...           ...   \n",
       "95    0.469478    0.000000    0.430745    0.175257  ...      0.589594   \n",
       "96    0.760850    0.000536    0.811464    0.842773  ...      0.386453   \n",
       "97    0.565181    0.029468    1.186909    1.608112  ...      0.992136   \n",
       "98    0.431906    0.000000    0.670172    0.766894  ...      0.393177   \n",
       "99    0.768720    0.000780    0.747760    0.753055  ...      0.348779   \n",
       "\n",
       "    cnn_feat_507  cnn_feat_508  cnn_feat_509  cnn_feat_510  cnn_feat_511  \\\n",
       "0       0.051652      0.165086      0.115031      0.013628      0.342411   \n",
       "1       0.219995      0.130606      0.004055      0.002865      0.242844   \n",
       "2       0.000000      0.144457      0.241148      0.000000      0.030442   \n",
       "3       0.481547      0.000000      0.012534      0.000000      0.053672   \n",
       "4       0.049234      0.027364      0.492153      0.000000      0.530912   \n",
       "..           ...           ...           ...           ...           ...   \n",
       "95      0.129699      0.101512      0.123570      0.000000      0.034644   \n",
       "96      0.115167      0.065269      0.626676      0.000000      0.084644   \n",
       "97      0.035201      0.079573      0.620282      0.000000      0.123685   \n",
       "98      0.000000      0.086598      0.016604      0.000000      0.195467   \n",
       "99      0.006385      0.075631      0.172105      0.006464      0.111514   \n",
       "\n",
       "    grammar_errors  sentence_count  avg_sentence_length  alignment_variance  \n",
       "0                6               3                 7.00        22973.555556  \n",
       "1               18               1                38.00            0.000000  \n",
       "2                0               0                 0.00            0.000000  \n",
       "3                8               1                16.00            1.250000  \n",
       "4               12               1                37.00       168054.619172  \n",
       "..             ...             ...                  ...                 ...  \n",
       "95              30               1                60.00         8266.500000  \n",
       "96              28               1                71.00            0.000000  \n",
       "97              14               2                35.50         7396.000000  \n",
       "98              24               4                13.75            0.000000  \n",
       "99              21               4                15.00            0.000000  \n",
       "\n",
       "[100 rows x 518 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd08c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c9adddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hybrid_features.csv\")\n",
    "\n",
    "# Drop image_id (not needed for training)\n",
    "X = df.drop(columns=['image_id', 'label'])\n",
    "y = df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e96f29b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31002536",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1a6417b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.00%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.95      0.95      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.2%}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Dyslexic', 'Dyslexic'], yticklabels=['Non-Dyslexic', 'Dyslexic'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec978e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_model3rd.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(rf_model, 'random_forest_model3rd.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c699a82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7c6d6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "561bb2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAHFCAYAAACn7hC1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+aklEQVR4nO3dCZxN9fvA8eeMZcyUdWRJ1pBdtmzZpShLi6UoRAvJkpCEpAzqV4oaPypFJSJ+bUoJEbIkKW12WRpbJts0uP/X8/2/7jR3Fo3rnjnnHp+313nNvd9zl++97r3nOc93s3w+n08AAACCEBHMnQAAABSBBAAACBqBBAAACBqBBAAACBqBBAAACBqBBAAACBqBBAAACBqBBAAACBqBBAAACBqBBDzt+++/l549e0rp0qUlV65ccvnll0vNmjVl4sSJcuTIEVufe+PGjdKkSRPJmzevWJYlkyZNCvlz6OM++eSTktXeeOMN89y6LVu2LM1+nTC3bNmyZn/Tpk2Deo5XXnnFPM+F0LpkVCcA9shu0+MCjps+fbr07dtXrrnmGhkyZIhUqlRJkpKSZP369TJ16lRZvXq1LFiwwLbnv/fee+XEiRPy7rvvSv78+aVUqVIhfw59DVdddZU4JXfu3PLaa6+lCRaWL18u27ZtM/uDpYFEwYIFpUePHpm+jwaJ+p7o/zWArEEgAU/Sg0mfPn3khhtukIULF0pkZGTyPi0bPHiwfPrpp7bW4YcffpD77rtPWrdubdtz1KtXT5zUuXNnefvtt+Xll1+WPHnyJJdrcFG/fn1JSEjIknpogKiZCK2D0+8JcKmhaQOeNG7cOHNgmTZtWkAQ4ZczZ05p165d8vVz586Z5o4KFSqY2xcqVEjuuece+f333wPup2feVapUkXXr1kmjRo0kOjpaypQpI+PHjzePkTLtf+bMGYmLi0tuAlDaDOG/nJL/Pjt37kwu+/LLL83zxcTESFRUlJQoUUJuv/12OXny5HmbNjSAad++vcmCaHPOtddeK2+++Wa6TQCzZ8+WESNGyJVXXmkOwi1btpRffvkl0+/znXfeaf7q4/gdO3ZM5s+fbzIy6RkzZozUrVtXChQoYJ5TswgaeKRcP1CzNz/++KPJbPjfP39Gx1/3WbNmmYCwWLFi5v9s69ataZo2Dh06JMWLF5cGDRqYYMNvy5Ytctlll8ndd9+d6dcKIH0EEvCcs2fPmoNwrVq1zEEkMzR7MWzYMJOt+OCDD2Ts2LEmY6EHID0YpXTgwAHp2rWrdOvWzdxWMw7Dhw+Xt956y+y/+eabTUZE3XHHHeay/3pmaUChj6MBz+uvv27qosGKHvz+/vvvDO+nQYDWWQ/CL730krz//vsmza/NAxoopfb444/Lrl275NVXXzVB12+//SZt27Y172FmaCCgr1Hr6KdBRUREhMlWZPTaHnjgAZk7d66p32233SYPP/ywec/9tMlJA7QaNWokv3+pm6H0Pd+9e7dppvrwww9N8JeaNo1o05IGfvr/qzQQ69ixownM9L4ALpIuIw54yYEDB/TU1telS5dM3f6nn34yt+/bt29A+TfffGPKH3/88eSyJk2amDLdl1KlSpV8N954Y0CZ3u6hhx4KKBs9erQpT23GjBmmfMeOHeb6vHnzzPXvvvvuvHXX2+hj+ulrjoyM9O3evTvgdq1bt/ZFR0f7/vzzT3N96dKl5r5t2rQJuN3cuXNN+erVq8/7vP76rlu3LvmxfvjhB7OvTp06vh49epjLlStXNu9ZRs6ePetLSkryPfXUU76YmBjfuXPnkvdldF//8zVu3DjDffo3pQkTJpjyBQsW+Lp37+6Lioryff/99+d9jQAyh4wELnlLly41f1N36rvuuuukYsWKsmTJkoDyIkWKmH0pVatWzZzZh4o2R2g24v777zfNEtu3b8/U/TQT06JFizSZGH1teiaeOjOSsnnH/zrUhbwWHZly9dVXm6zE5s2bzdl/Rs0a/jpqE4qOZsmWLZvkyJFDRo0aJYcPH5b4+PhMP68282SWdrbVDI82xej7OXnyZKlatWqm7w8gYwQS8BxNZ2vfhR07dmTq9noAU0WLFk2zT/sO+Pf7aZ+F1LSN/tSpUxIqemD+4osvTLr+oYceMtd1e/HFF897P61rRq/Dv/98r8Xfn+RCXov2SdAhttq0o00F5cuXN/1H0rN27Vpp1apV8qiar7/+2gQe2k/jQp83vdd5vjpqMHX69GkTCNI3AggdAgl4jp7l6ln5hg0b0nSWTI//YLp///40+/bt22cCk1DRzo8qMTExoDx1PwylB2Nt+9fOi2vWrDGjIAYOHGja/M/3WjJ6HSqUryUlPUjra9BAQoOKjGjdNQPx0UcfSadOnUx/jtq1awf1nOl1Ws2IvicakGmmR4OpRx99NKjnBJAWgQQ8STviaRcCHX6ZXudE7cGvB2nVvHlz89ffWdJPz5R/+uknE5SEin/kgU6UlZK/LhkFRjrKQYdYqm+//TbD22pdtenAHzj4zZw502Rp7BoaqSMntPlAO2p27979vAf/7Nmzm9fkp1kIHYFhV5ZHO45qk4Y+96JFiyQ2NtY0bWhHTwAXj3kk4El69q5DL3VCKh29oaMyKleubAIInXFSRyjoME498OmEVdoXQQ8uOtpAR2HoyIKRI0eavgaDBg0KWb3atGljhj326tVLnnrqKXNQ1aGfe/bsCbidntlrQKDt+jq6QFPy/pER2r8gI6NHjzZn+82aNTP9DvS5dJ6Hjz/+2Iza0H4JdtFRJf9GX8/zzz8vd911l3nPNTvw3HPPpTtEV/swaAZjzpw5ZgSHZnOC6deg78mKFStk8eLFpllDh4zqsFL9P9BRITrrKYDgEUjAszQboZ0iX3jhBZkwYYIZtqlpdW3D1wNZv379km+rQYf2QdD5DPTMXw+4N910kzl7Ta9PRLB0uKQO5dQmCh0+mi9fPundu7cJXvSvn6bg9cCnB0Gtt07trYGPDjf19zFIjwZFq1atMsM6NZWvZ/TaYXTGjBkXNEOkXTT7owGR/n9oEKeZDP1/0r4gemBPPd+ENkno/r/++ktKliwZMM9GZnz++efm/1CDwpSZJQ3eNIjQIaorV640HVsBBMfSoRtB3hcAAFzi6CMBAACCRiABAACCRiABAACCRiABAIBHffXVV6Zjs05Kp0OgdTXklLSbpC78p/t1cUBdKFDX6rkQBBIAAHjUiRMnpHr16jJlypR09+uwcB2Srft17hwdIq2LF+pIqcxi1AYAAJcAy7LMKrodOnQw1/Xwr5kIHY7uXx1XZ90tXLiwGaKtq/RmBhkJAADCRGJioiQkJARsqafczyxdj0jnqUk5N41ODqcL8el8NJf0hFRRNf6ZaAjAP46uSz+9CVzKcmUPn+PSsPYFzWRtKenEddrP4UJpEKE0A5GSXr+QFYA9GUgAAODVdYQeeeSRgLL0ppi/mAXwtMnjQhbFI5AAAMBuVmh6EmjQcLGBg592rPRnJooWLZpcHh8fnyZLcT70kQAAwG6WFZothHTBOg0mdE0aP10tWRe1a9CgQaYfh4wEAABhkpG4UMePH5etW7cGdLD87rvvzMrAurKwjtgYN26clCtXzmx6OTo62ixsmFkEEgAAeNT69eulWbNmydf9/Su6d+9uVsEdOnSoWSW4b9++cvToUalbt65ZeTh37tyX9jwSjNoA0seoDcChURt1AjtIBuvUuufFbchIAADg0aaNrODdVwYAAGxHRgIAALtZoR1x4SYEEgAA2M3ybgOAd18ZAACwHRkJAADsZtG0AQAAgmV5twHAu68MAADYjowEAAB2s2jaAAAAwbK82wBAIAEAgN0s72YkvBsiAQAA25GRAADAbpZ3z9sJJAAAsJvl3UDCu68MAADYjowEAAB2i/BuZ0sCCQAA7GZ5twHAu68MAADYjowEAAB2s2jaAAAAwbK82wDg3VcGAABsR0YCAAC7WTRtAACAYFnebQAgkAAAwG6WdzMS3g2RAACA7chIAABgN8u75+0EEgAA2M2iaQMAACANMhIAANjN8u55O4EEAAB2s2jaAAAASIOMBAAAdrO8e95OIAEAgN0s7wYS3n1lAADAdmQkAACwm+XdzpYEEgAA2M3ybgMAgQQAAHazvJuR8G6IBAAAbEdGAgAAu1nePW8nkAAAwG4WTRsAAABpkJEAAMBmloczEgQSAADYzPJwIEHTBgAACO9AYsaMGfLee++lKdeyN99805E6AQAQMlaINhdyRSAxfvx4KViwYJryQoUKybhx4xypEwAAoWzasEKwuZErAoldu3ZJ6dKl05SXLFlSdu/e7UidAABAmAQSmnn4/vvv05Rv2rRJYmJiHKkTAAChYnk4I+GKURtdunSR/v37S+7cuaVx48ambPny5TJgwACzDwCAcGa5NAjwTCDx9NNPm+aNFi1aSPbs/1+lc+fOyT333EMfCQBA2LMIJOyVM2dOmTNnjowdO9Y0Z0RFRUnVqlVNHwkAAOBerggk/MqXL282AAA8xRLPciyQeOSRR0wG4rLLLjOXz+f555/PsnoBABBqFk0bobdx40ZJSkpKvnwpvvkAAIQ7xwKJpUuXpnsZAACvsTx8UuyKeST++OOPDPelN78EAADhxPLwPBKuCCR0hMYHH3yQpvy5556TunXrOlInAAAQJoHEsGHDpHPnzvLggw/KqVOnZO/evdK8eXN59tlnzbBQAADCmUVGwl6DBw+WNWvWyNdffy3VqlUzm84loc0a7dq1c7p6AABcHIvVP21XpkwZqVy5suzcuVMSEhKkU6dOUrhwYaerBQAA3B5I+DMRW7duNVmIuLg4efjhh00wcfToUaerBwDARbFo2rCX9ofQPhKrV6+WihUrSu/evc3cEr///rvpiAkAQDizPBxIuGKK7MWLF0uTJk0Cyq6++mpZuXKlPPPMM47VCwCAULBcGgR4JiPhDyK0aeOzzz4zIzf8b/zIkSMdrh0AAOHnzJkz8sQTT0jp0qXNAAbti/jUU0+Z1bU9l5E4fPiw6Q+hM1xq8PDbb7+ZF6xNHPnz5zfzSQAAELasrH/KCRMmyNSpU+XNN980gxnWr18vPXv2lLx588qAAQO8lZEYNGiQ5MiRQ3bv3i3R0dHJ5dpvYtGiRY7WDQCAcOwjsXr1amnfvr3cfPPNUqpUKbnjjjukVatWJqAIpQi39JHQyOmqq64KKC9Xrpzs2rXLsXoBAOAmiYmJZoqElJuWpef666+XJUuWyK+//mqub9q0yfQ9bNOmjfcCiRMnTgRkIvwOHTokkZGRjtQJAAC3ZSRiY2NN00TKTcsymjX6zjvvlAoVKpisf40aNWTgwIGmzHOBROPGjWXmzJnJ1/XN0s4gOkV2s2bNHK0bAABuCSSGDx8ux44dC9i0LD26xMRbb70l77zzjnz77bemr4T2OdS/nutsqQFD06ZNTbvN33//LUOHDpUff/xRjhw5YiarAgAAYrL0mc3UDxkyRB577DHp0qWLua7zMml3Ac1gdO/e3VsZiUqVKpkZLa+77jq54YYbTFPHbbfdZial0vkkAAAIZ5YDnS1PnjwpERGBh/ls2bJ5c/inKlKkiIwZM8bpagAA4Inhn23btjWTOpYoUcIM/9ST8+eff17uvfdebwQSmoHILF2HAwAAZN7kyZPNpI59+/aV+Ph4ufLKK+WBBx6QUaNGSShZPp/PJw7QdIumaf7t6fU2Z8+evaDHjqrR7yJrB3jT0XVTnK4C4Dq5suCUulifBSF5nL1xt4rbOJaR2LFjh1NPDQBAlrI8vNaGY4FEyZIlnXpqAACylOXhQMIVozZ0TOvHH3+cfF2Hf+bLl08aNGjAzJYAALiYKwKJcePGmZXJ/HODT5kyRSZOnCgFCxY063AAABDWrBBtLuSK4Z979uyRsmXLmssLFy40C4vcf//90rBhQzNRFQAA4cyiacNel19+uVlK3L+AV8uWLc3lXLlyyalTpxyuHQAAcHUgobNZ9u7d22y6Spkueap0mmxd+hTu1rDm1TJv0gOyffEzcmrjFGnbNO28HyMeaGP2H1n9vHw2fYBULFPEkboCTpsz+21p3aq51KlRVbp0vE2+3RDaJZ3hTpYDM1teUoHEyy+/LPXr15eDBw/K/PnzJSYmxpRv2LAh5KuUIfQui4qUzb/ulUHj56a7f3CPltK/WzOz//puz8ofhxPk46kPy+XRrOyKS8uniz6RieNj5b77+8iceQulZs1a0veB+2T/vn1OVw02szwcSDg2IZWdmJDKOZqR6DRomny47J+ZSzUT8fI7S+U/b3xhrufMkV12LRknT7z4P3ltPouyZSUmpHJW1y4dpWKlSvLEqH+WA+jQtrU0a95SBgwa7GjdLmVZMSFVqQEfheRxdr54i7iNKzIS2nzx1FNPmU6X8JZSxWKk6BV55YvVPyeX/Z10RlZs2Cr1qpdxtG5AVkr6+2/5acuPUr/B9QHl9Rs0lE3fbXSsXsgaloczEq4IJAYPHiz/+9//pHTp0qa/xLvvviuJiYlOVwshUKRgHvM3/shfAeXxh/+SwjH/vw+4FBz986iZ7t/fdOsXE1NQDh066Fi9kEUs7w7/dEUg8fDDD5v+ELrpkuL9+/eXokWLSr9+/eTbb78973014EhISAjYfOcubG0O2C91C5oG1h5sVQP+VeqzSv0euPVMEwibQMKvevXq8uKLL8revXtl9OjR8uqrr0qdOnVM+euvv57ugSc2Nlby5s0bsJ35Y4Mj9UdaBw4lmL+psw9XFMidJksBeFn+fPklW7ZscujQoYDyI0cOm6wEvM2iaSNrJCUlydy5c6Vdu3amuaN27dommOjUqZOMGDFCunbtmuY+w4cPl2PHjgVs2QvXcqT+SGvn3sOy/+AxaVGvQnJZjuzZpFGtsrJm03ZH6wZkpRw5c0rFSpVlzarADsZrVq2S6tfWcKxeyBqWhwMJV8xsqc0XM2bMkNmzZ5uI/e6775YXXnhBKlT45+DTqlUrady4cZr7RkZGmi0lKyJbltQb/++yqJxydfErAjpYVitfTI4mnJQ9B46aERtDerWSrbvjZevugzK0141y6nSSzFnE+HlcWu7u3lNGPDZUKlWpItWr15D5782R/fv3S8fOXZyuGmxmuTMG8E4goc0X2skyLi5OOnToIDly5EhzG+070aULXzY3qlmppCx+dUDy9YmP3m7+zvpgjdw/+i0z7DNXZE6ZNLyz5M8TLet+2Cm39Jkix0/SoRaXlptat5Fjfx6VaXGvyMGD8VK2XHl5eeo0ufLKYk5XDQjveSR0hc9QLivOPBJA+phHAnBmHolyQz4NyeP89uxN4jauyEiUKFFC1q9fLzt37jRtQDoMtEaNGq5tDwIA4EJYHj6cOR5ILF26VHr16mWyEv7kiD+Y0JEa6fWLAAAA7uDoqI2tW7fKLbfcYma2fP/99+Wnn36SLVu2yHvvvSdXXXWVtGnTRrZvp2c/ACC8WYzasMekSZOkXr16smTJkoByHa1x6623muXEdfTG5MmTHasjAAAXy3JnDBD+GYlly5bJwIED092nkZfu06YPAADgTo5mJHbv3i1Vq1bNcH+VKlVM3wkAAMJZRIR3UxKOBhLHjx+X6OjoDPfrvpMnT2ZpnQAACDXLu3GE86M2tHPlgQMH0t2Xek56AADgLo4HEi1atEh3MS7tI8GqeAAAL7A8fCxzNJDYsWOHk08PAECWsLwbRzgbSIRyWmwAANzK8nAk4aplxJWO4tizZ4/T1QAAAOHQRyI1XW8jKSnJ6WoAABAyloczEq4LJAAA8BrLu3GE+5o2GjVqJFFRUU5XAwAAhGNG4pNPPnG6CgAAhJTl4ZSEawKJX3/91ay9ER8fL+fOnQvYN2rUKMfqBQDAxbK8G0e4I5CYPn269OnTRwoWLChFihQJiNz0MoEEAADu5IpA4umnn5ZnnnlGhg0b5nRVAAAIOcvDKQlXBBJHjx6Vjh07Ol0NAABsYXk3jnDHqA0NIhYvXux0NQAAQDhmJMqWLSsjR46UNWvWmJktc+TIEbC/f//+jtUNAICLZXk4JWH50lt6M4uVLl36vG/+9u3bL+jxomr0C0GtAO85um6K01UAXCdXFpxSXzduWUgeZ+3jTcVtXJGRYBVQAICXWR7OSLiij0RKmiBxQZIEAACEUyAxc+ZM0z9Cp8fWrVq1ajJr1iynqwUAwEWzrNBsbuSKpo3nn3/edLbs16+fNGzY0GQkvv76a3nwwQfl0KFDMmjQIKerCABA0Cy3RgFeCSQmT54scXFxcs899ySXtW/fXipXrixPPvkkgQQAAC7likBi//790qBBgzTlWqb7AAAIZ5Z3ExLu6COh80jMnTs3TfmcOXOkXLlyjtQJAIBQNm1YIdjcyBUZiTFjxkjnzp3lq6++Mn0k9M1auXKlLFmyJN0AAwAAuIMrAonbb79dvvnmG9PpcuHChaazZaVKlWTt2rVSo0YNp6sHAMBFsdyZTPBOIKFq1aolb7/9ttPVAAAg5CwPRxKOBhIRERH/+ubq/jNnzmRZnQAAQJgEEgsWLMhw36pVq8ywUGa5BACEO4uMhD10rojUfv75Zxk+fLh8+OGH0rVrVxk7dqwjdQMAIFQs78YR7hj+qfbt2yf33XefmRpbmzI2btwob775ppQoUcLpqgEAcFEsDw//dDyQOHbsmAwbNszMJfHjjz+aIZ+ajdB1NwAAgLs52rQxceJEmTBhghQpUkRmz56dblMHAADhznJnMiH8A4nHHnvMrPSp2QhtxtAtPe+//36W1w0AgFCxPBxJOBpI6CJdXn5zAQDwOkcDiTfeeMPJpwcAIEtYHj5nds3MlgAAeFWEhyMJx0dtAACA8EVGAgAAm1neTUgQSAAAYDfLw5EETRsAANgswgrNdqH27t0r3bp1k5iYGImOjpZrr71WNmzYENLXRkYCAAAPOnr0qDRs2FCaNWsmixYtkkKFCsm2bdskX758IX0eAgkAADzYtDFhwgQpXry4zJgxI7msVKlSIX8emjYAALCZZYVmS0xMlISEhIBNy9LzwQcfSO3ataVjx44mG1GjRg2ZPn16yF8bgQQAAGEiNjZW8ubNG7BpWXq2b98ucXFxUq5cOfnss8/kwQcflP79+8vMmTNDWifL5/P5xGOiavRzugqAKx1dN8XpKgCukysLGvlv+e+6kDzO/B7V0mQgIiMjzZZazpw5TUZi1apVyWUaSKxbt05Wr14toUIfCQAAbBYRoi4SGQUN6SlatKhUqlQpoKxixYoyf/58CSWaNgAA8KCGDRvKL7/8ElD266+/SsmSJUP6PGQkAADw4KiNQYMGSYMGDWTcuHHSqVMnWbt2rUybNs1soURGAgCAMBm1cSHq1KkjCxYskNmzZ0uVKlVk7NixMmnSJOnatauEEhkJAAA86pZbbjGbnQgkAACwWYSH19ogkAAAwGaWd+MIAgkAAOxmeTiSoLMlAAAIGhkJAABsZnk3IUEgAQCA3SI8HEnQtAEAAIJGRgIAAJtZ4l0EEgAA2MyiaQMAACAtMhIAAITJMuJhG0h88MEHmX7Adu3aXUx9AADwHMvDTRuZCiQ6dOiQ6Tfq7NmzF1snAADgpUDi3Llz9tcEAACPsrybkKCPBAAAdrM8HEkEFUicOHFCli9fLrt375a///47YF///v1DVTcAADwhwrtxxIUHEhs3bpQ2bdrIyZMnTUBRoEABOXTokERHR0uhQoUIJAAAuIRc8DwSgwYNkrZt28qRI0ckKipK1qxZI7t27ZJatWrJc889Z08tAQAI86YNKwSbJwKJ7777TgYPHizZsmUzW2JiohQvXlwmTpwojz/+uD21BAAgjFkh2jwRSOTIkSM5KipcuLDpJ6Hy5s2bfBkAAFwaLriPRI0aNWT9+vVSvnx5adasmYwaNcr0kZg1a5ZUrVrVnloCABDGIlzaLOFIRmLcuHFStGhRc3ns2LESExMjffr0kfj4eJk2bZoddQQAIKxZVmg2T2QkateunXz5iiuukE8++STUdQIAAGGCCakAALCZ5dZ0ghOBROnSpc/7hmzfvv1i6wQAgKdY3o0jLjyQGDhwYMD1pKQkM0nVp59+KkOGDAll3QAAgNcCiQEDBqRb/vLLL5vRHAAAIBCjNjKhdevWMn/+/FA9HAAAnmExauPfzZs3z6y7AQAAAtHZMtWEVCnfEJ/PJwcOHJCDBw/KK6+8Eur6AQAALwUS7du3DwgkIiIizHwSTZs2lQoVKogbHF03xekqAK6Uv04/p6sAuM6pjVPCpx+BFwKJJ5980p6aAADgUZaHmzYuOEjSFT91OuzUDh8+bPYBAIBLxwVnJLRPRHp0OfGcOXOGok4AAHhKhHcTEpkPJF566aXk9Myrr74ql19+efK+s2fPyldffeWaPhIAALhJBIGEyAsvvJCckZg6dWpAM4ZmIkqVKmXKAQDApSPTgcSOHTvM32bNmsn7778v+fPnt7NeAAB4huXhzpYX3Edi6dKl9tQEAACPivBuHHHhozbuuOMOGT9+fJryZ599Vjp27BiqegEAAC8GEsuXL5ebb745TflNN91kOlwCAIBArLWRwvHjx9Md5pkjRw5JSEgIVb0AAPCMCLdGAU5kJKpUqSJz5sxJU/7uu+9KpUqVQlUvAAA8dbCNCMHmiYzEyJEj5fbbb5dt27ZJ8+bNTdmSJUvknXfeMSuAAgCAS8cFBxLt2rWThQsXyrhx40zgEBUVJdWrV5cvv/xS8uTJY08tAQAIY5Z3WzYuPJBQ2tnS3+Hyzz//lLffflsGDhwomzZtMrNcAgCAf9BHIh2agejWrZtceeWVMmXKFGnTpo2sX78+tLUDAADeyUj8/vvv8sYbb8jrr78uJ06ckE6dOklSUpLMnz+fjpYAAGTAwwmJzGckNOOgwcKWLVtk8uTJsm/fPvMXAAD8+8yWodjCOiOxePFi6d+/v/Tp00fKlStnb60AAIC3MhIrVqyQv/76S2rXri1169Y1/SIOHjxob+0AAPBIZ8uIEGxhHUjUr19fpk+fLvv375cHHnjATEBVrFgxOXfunHz++ecmyAAAAJfWFNkXPGojOjpa7r33Xlm5cqVs3rxZBg8ebBbxKlSokJljAgAAXDouasbNa665RiZOnGhGc8yePTt0tQIAwEMi6Gx5ftmyZZMOHTqYDQAABLLEpVGAWwIJAACQMbdmE0LBrYuJAQCAMEBGAgAAm0V4OCNBIAEAgM0st47dDAGaNgAAQNDISAAAYLMI7yYkCCQAALCb5eFAgqYNAAAQNDISAADYLMLDKQkyEgAAXAJTZMfGxprRIwMHDpRQIpAAAMDj1q1bJ9OmTZNq1aqF/LEJJAAA8PAy4sePH5euXbvK9OnTJX/+/KF+aQQSAADYLUKskGyJiYmSkJAQsGnZ+Tz00ENy8803S8uWLW16bQAAICwyErGxsZI3b96ATcsy8u6778qGDRvOe5uLxagNAADCxPDhw+WRRx4JKIuMjEz3tnv27JEBAwbI4sWLJVeuXLbViUACAIAwmdkyMjIyw8AhNc1ExMfHS61atZLLzp49K1999ZVMmTLFNIlky5btoutEIAEAgAfnkWjRooVs3rw5oKxnz55SoUIFGTZsWEiCCEUgAQCAB+XOnVuqVKkSUHbZZZdJTExMmvKLQSABAIDNLO9ObEkgAQDApTJF9rJly0L+mAz/BAAAQSMjAQCAzSx3JCRsQSABAIDNIsS7vPzaAACAzchIAABgM8vDbRsEEgAA2MwS7yKQAADgEhn+aQf6SAAAgKCRkQAAwGaWeBeBBAAANrM8HEnQtAEAAIJGRgIAAJtZHk5JEEgAAGCzCPEuL782AABgMzISAADYzKJpAwAABMsS76JpAwAABI2MBAAANrNo2gAAAMGKEO8ikAAAwGaWhzMSXg6SAACAzchIAABgM0u8i0ACAACbWR6OJFzRtHHs2DE5cuRImnItS0hIcKROAAAgTAKJLl26yLvvvpumfO7cuWYfAADhLEKskGxu5IpA4ptvvpFmzZqlKW/atKnZBwBAuDdtWCHY3MgVgURiYqKcOXMmTXlSUpKcOnXKkToBAIAwCSTq1Kkj06ZNS1M+depUqVWrliN1AgAgVKwQ/XMjV4zaeOaZZ6Rly5ayadMmadGihSlbsmSJrFu3ThYvXux09QAAuCiWO2MA72QkGjZsKKtXr5bixYubDpYffvihlC1bVr7//ntp1KiR09UDAABuzkioa6+9Vt5++22nqwEAQMhFuLRZIqwDCZ0fIk+ePMmXz8d/OwAAwpHl3TjCuUAif/78sn//filUqJDky5cv3QVNfD6fKT979qwjdQQAIBQsAonQ+/LLL6VAgQLJl728MhoAAF7lWCDRpEmTgImnAADwKsvDfSRcMWpj5MiR6TZf6Bocd955pyN1AgAgVCKs0Gxu5IpAYubMmWYI6LZt25LLli1bJlWrVpWdO3c6WjcAAODyQELniyhVqpQZAjp9+nQZMmSItGrVSnr06CErV650unoAAFwUi5kt7ZU3b16z+ueIESPkgQcekOzZs8uiRYuSZ7kEACCcWe6MAbyTkVCTJ0+WF154wfSJKFOmjPTv399MmQ0AANzLFYFE69atZcyYMaavhM5uuXHjRmncuLHUq1dPJk6c6HT1AAC4KJaHmzZcEUjoEuLaT+KOO+4w16OioiQuLk7mzZtnshQAAISzCA+P2nBFH4nPP/883fKbb75ZNm/enOX1AQAAYZSRUCtWrJBu3bpJ/fr1Ze/evaZs1qxZ8vPPPztdNQRpzuy3pXWr5lKnRlXp0vE2+XbDeqerBGSphjWvlnmTHpDti5+RUxunSNum1dLcZsQDbcz+I6ufl8+mD5CKZYo4UlfYy6Jpw17z58+XG2+80TRpaP+IxMREU/7XX3/JuHHjnK4egvDpok9k4vhYue/+PjJn3kKpWbOW9H3gPtm/b5/TVQOyzGVRkbL5170yaPzcdPcP7tFS+ndrZvZf3+1Z+eNwgnw89WG5PDoyy+sK+0dtWCHY3MgVgcTTTz8tU6dONXNI5MiRI7m8QYMG8u233zpaNwRn1psz5Nbbb5fb7ugoZa6+WoYOHyFFihaRuXNmO101IMss/nqLjHnlI/nfl+mPQHvormYy8bXPzP4t2/ZL75GzJCpXDuncunaW1xX2skK0uZErAolffvnFjNJIb/nwP//805E6IXhJf/8tP235Ueo3uD6gvH6DhrLpu42O1Qtwk1LFYqToFXnli9X/NN/+nXRGVmzYKvWql3G0bkDYdbYsWrSobN261cxumZLOaqlzSpyPNoP4m0L8fNkiJTKS1KBTjv551KydEhMTE1AeE1NQDh066Fi9ADcpUjCP+Rt/5K+A8vjDf0mJov+/MjK8I8Kt7RJeyUjobJYDBgyQb775xiwnvm/fPjOfxKOPPip9+/Y9731jY2PNzJgpt2cnxGZZ3ZGx1EvD+3w+losHUtHvRUr6FUldhvBnebhpwxUZiaFDh5qVPps1ayanT582zRyaUdBAol+/fue97/Dhw+WRRx5Jk5GAc/Lnyy/ZsmWTQ4cOBZQfOXLYZCUAiBw4lGD+Fo7Jk3xZXVEgd5osBeBmrshIqGeeecYceNauXStr1qyRgwcPytixY//1fhpwaF+KlBvNGs7KkTOnVKxUWdas+jqgfM2qVVL92hqO1Qtwk517D8v+g8ekRb0KyWU5smeTRrXKyppN2x2tG2xgeTcl4YqMhF90dLTUrk1vZS+4u3tPGfHYUKlUpYpUr15D5r83R/bv3y8dO3dxumpAlrksKqdcXfyKgA6W1coXk6MJJ2XPgaPy8jtLZUivVrJ1d7xs3X1Qhva6UU6dTpI5i5hzxWsst0YB4RxI3HbbbZm+7fvvv29rXRB6N7VuI8f+PCrT4l6RgwfjpWy58vLy1Gly5ZXFnK4akGVqViopi18dkHx94qO3m7+zPlgj949+S/7zxheSKzKnTBreWfLniZZ1P+yUW/pMkeMnAzuQA25m+Rzq1dOzZ89M33bGjBkX9NinzwRRIeASkL/O+fscAZcinXXUbmu3HwvJ41xXJq+4jWMZiQsNDgAACFeWeJcrOlueOnVKTp48mXx9165dMmnSJFm8eLGj9QIAAGEQSLRv315mzpxpLutMltddd5385z//MeW6nDgAAGHN8u6oDVcEErqeRqNGjczlefPmSZEiRUxWQoOLl156yenqAQBwUSwPr/7piuGf2qyRO3duc1mbM3RER0REhNSrV88EFAAAhDPLnTGAdzISZcuWlYULF8qePXvks88+k1atWpny+Ph4M8EUAABwJ1cEEqNGjTLTYeuiXXXr1pX69esnZydq1GAmRABAeLO820XCHU0bd9xxh1x//fVm5sPq1asnl7do0UJuvfVWR+sGAMBFs8SzXJGReOONN8yqnZp90L4Rfjp6o0KFf+ahBwAA7uKKQEJX8CxcuLD06tVLVq1a5XR1AAAI+1EbsbGxUqdOHTOYoVChQtKhQwf55ZdfvBlI/P777/LWW2/J0aNHzVLimoWYMGGCHDhwwOmqAQAQklEbVgi2C7F8+XJ56KGHzIran3/+uZw5c8YMZjhx4oQ31trIiI7U0KBCmzt+/vlnuemmm0ymom3btgHNHufDWhtA+lhrA3BmrY3vdv8Vkse5tsT/T5UQjIMHD5rMhAYYjRs3Fk9lJFLSF9mwYUMzckMDh82bN0uPHj3k6quvlmXLljldPQAAHBu1kZiYKAkJCQGblmXGsWP/v3BYgQIFQvraXBNI/PHHH/Lcc89J5cqVpWnTpubN+eijj2THjh2yb98+M0lV9+7dna4mAACORRKxsbFmcELKTcv+jTY+PPLII2aEZJUqVbzXtKHNFp9++qlcc8010rt3b7nnnnvSREwaTFx11VVy7ty5f308mjaA9NG0ATjTtLFpT2iaNioUypkmAxEZGWm289G+Eh9//LGsXLnSHEs9N4+ENmesWLHCTImdkaJFi5rsBAAA4cYK0UQSmQkaUnv44Yflgw8+kK+++irkQYQrAgnNMDRo0ECefvpp2blzp1iWJaVLlzaTVN19993mutK/JUuWdLq6AACExVobPp/PBBELFiwwfQz12GoHR/tI6Its166d3H///bJ3716pWrWq6SOhC3VpB0tmtQQAeIHlwBTZ2pyhoyDfeecdM5eETqmg26lTp7yTkdAhnppq+eKLL8z8ESl9+eWXZvIMXUpc+0wAAIDMi4uLM391AENKM2bMMCfrnggkZs+eLY8//niaIEI1b95cHnvsMXn77bcJJAAA4c3K+qfMqrEUjjZtfP/992bCqYy0bt1aNm3alKV1AgDAC1NkZxVHA4kjR46YNTYyovt02mwAAOBOjjZtnD17VrJnz7gK2bJlM3ODAwAQzix3JhPCP5DQ9hvt8JHRmNjMTvsJAICbWeJdjgYSmZnymo6WAAC4l6OBhA5BAQDA8yzxLMdntgQAwOssD0cSrln9EwAAhB8yEgAA2MzybkKCQAIAALtZ4l0EEgAA2M0Sz6KPBAAACBoZCQAAbGZ5OCVBIAEAgM0s78YRNG0AAIDgkZEAAMBmlngXgQQAAHazxLNo2gAAAEEjIwEAgM0sD6ckCCQAALCZ5d04gqYNAAAQPDISAADYzBLvIpAAAMBulngWgQQAADazPBxJ0EcCAAAEjYwEAAA2s7ybkCCQAADAbpZ4F00bAAAgaGQkAACwmeXhlASBBAAAtrPEq2jaAAAAQSMjAQCAzSzvJiQIJAAAsJsl3kXTBgAACBoZCQAAbGZ5OCVBIAEAgM0sDzduEEgAAGA3SzyLPhIAACBoZCQAALCZJd5FIAEAgM0sD0cSNG0AAICgkZEAAMBmlocbNwgkAACwmyWeRdMGAAAIGhkJAABsZol3EUgAAGAzy8ORBE0bAAAgaGQkAACwmeXhxg0CCQAAbGZ5N46gaQMAAASPQAIAAASNpg0AAGxmebhpg0ACAACbWR7ubEnTBgAACBoZCQAAbGZ5NyFBIAEAgN0s8S6aNgAAQNDISAAAYDdLPItAAgAAm1kejiRo2gAAAEEjIwEAgM0s7yYkCCQAALCbJd5F0wYAAFkRSVgh2ILwyiuvSOnSpSVXrlxSq1YtWbFiRUhfGoEEAAAeNWfOHBk4cKCMGDFCNm7cKI0aNZLWrVvL7t27Q/Ycls/n84nHnD7jdA0Ad8pfp5/TVQBc59TGKfY/R1JoHicqx4Xdvm7dulKzZk2Ji4tLLqtYsaJ06NBBYmNjQ1InMhIAAGRBZ0srBNuF+Pvvv2XDhg3SqlWrgHK9vmrVqpC9NjpbAgAQJhITE82WUmRkpNlSO3TokJw9e1YKFy4cUK7XDxw4ELI6eTKQyOXJVxV+9MOuqbPhw4en+yGHN1O4+Hd8Ny49uUJ0XHry6VgZM2ZMQNno0aPlySefzPA+VqpUhvZoSF12MTzZRwLukJCQIHnz5pVjx45Jnjx5nK4O4Bp8N5AVGQlt2oiOjpb33ntPbr311uTyAQMGyHfffSfLly+XUKCPBAAAYSIyMtIEnym3jLJaOXPmNMM9P//884Byvd6gQYOQ1YlGAAAAPOqRRx6Ru+++W2rXri3169eXadOmmaGfDz74YMieg0ACAACP6ty5sxw+fFieeuop2b9/v1SpUkU++eQTKVmyZMieg0ACttF0m3YCojMZEIjvBrJS3759zWYXOlsCAICg0dkSAAAEjUACAAAEjUACAAAEjUACrrRz504z85pOmhIqTZs2NavgAU7p0aOHWSwpVJYtW2a+J3/++WfIHhO4UAQSYfpjpD8e48ePDyhfuHBhSKc9Pd8B3r/lzp1bKleuLA899JD89ttv4mbvv/++jB071ulqwOXfK91y5Mhh1iO44YYb5PXXX5dz586JG+mkQjqkT2fJBJxCIBGmcuXKJRMmTJCjR4868vxffPGF+QHbtGmTjBs3Tn766SepXr26LFmyRNyqQIECJvABMnLTTTeZz7UGzIsWLZJmzZqZ6YRvueUWOXPmjLiNzlxYpEgR208ggPMhkAhTLVu2ND8g51tPfv78+SZboGPVS5UqJf/5z38C9muZBgH33nuvOcCWKFHCzHqWGTExMeb5y5QpI+3btzeBha5736tXL7PanP4QR0REyPr16wPuN3nyZDMRio461iCoa9eucsUVV0hUVJSUK1dOZsyYkeFzbtmyRdq0aSOXX365OVvU2dp0dTt/ild/VFesWJF8e329BQsWNAeG9Jo2dL76oUOHSvHixc17pM//2muvZer1w5v0c6Cf62LFiknNmjXl8ccfl//9738mqHjjjTfMd0WDipQ0wND7aOZCzZs3T6pWrWo+0/o90e/qiRMn0n0+/R5MnDjRfI/09hqM6/39+/S+Gtz4R+lrE4Z+T0eMGJFh08bXX38tTZo0MWss5M+fX2688UbHTjhwaSCQCFPZsmUzQYAemH///fc0+3UN+k6dOkmXLl1k8+bNZmW4kSNHmh/DlPRgq1Onbty40UxY0qdPH/n5558vuD4aNOiZ265du8xza5CiP4KpAwO97k8ha300ONAfac1oxMXFmQN/ejQY0B/Ha6+91gQnn376qfzxxx/mNaYMEjS40IWQNFOiP7bTp0+XokWLpvuY99xzj7z77rvy0ksvmeefOnWqCVKAlJo3b24O8No01rt3b/PZ8wenSmcJPH78uPksavmdd95pAg79TOmB/rbbbksOBFJ74oknzHdCP/s//vijDBo0SLp162YWU9LvyJtvvilr1641n1Gl0xprEJ3RSo/ap6hFixbmBGL16tWycuVKadu2rQnuAdvohFQIL927d/e1b9/eXK5Xr57v3nvvNZcXLFigv1bm8l133eW74YYbAu43ZMgQX6VKlZKvlyxZ0tetW7fk6+fOnfMVKlTIFxcXl+Fz79ixwzzHxo0b0+z76aefzL45c+aY6/o3f/78vtOnT5vr3333nc+yLPMYqm3btr6ePXtm6nlGjhzpa9WqVcBt9uzZY27zyy+/mOuJiYm+GjVq+Dp16uSrXLmyr3fv3gG3b9KkiW/AgAHmst5H7/v5559n+Fpx6X6vUuvcubOvYsWK5rJ+hyZMmJC8r0OHDr4ePXqYyxs2bDCfq507d/7rcxw/ftyXK1cu36pVqwJu06tXL9+dd96ZfH3u3Lm+yMhI3/Dhw33R0dHJn3e1dOlS83xHjx411/V+DRs2vIh3AbhwZCTCnPaT0LMWPbNPSc+GGjZsGFCm17VDZMqzk2rVqiVf1jMgTdHGx8eb661btzZn6LrpGc6/8Z91+dtrtXd69uzZZcGCBea6pn61zVmzFUqzH5oR0CyDNjGsWrUqw8fWLMfSpUuT66NbhQoVzL5t27aZv9q08dZbb5kmnVOnTsmkSZMyfDw9c9OsjmY5gMx8tv2fa81K+DNt+l35+OOPTQZCaeZCMwLatNGxY0eTEcuoWUG/s6dPnzYdOlN+rmfOnJn8mVb6OJrV0GZMzSCWL18+w3r6MxJAVmKtjTDXuHFj0waqbbnaZJDeD1/KstS0d3pKeh9/D/VXX33VHJDTu116NHhRpUuXTj6wa1OD/ujqD+E777wTcHDXQEWbQvSHWPtY6A+gjv547rnn0jy21klTtBo4pZay6cIfjBw5csRsl112Wbp11fZoILP0s+3/XGuT2GOPPWaaDnTTwLhRo0ZmnwanukSzfg4XL15smh61ie2bb75Jvr+f/3umn3/tk5FSyjU4Tp48aQJpfex/GxnF5xpOICPhAXqm8uGHHwac0VeqVMm0j6ak+/VsRn+QMkN/3MqWLWu2f1spTn8UtR1Xfyxr1KiRXK5nbxokvPLKK5KUlGQCipS0o6UGQJpJ0CAjo86e2vFN25D1R9tfJ//mDxb0LE7bmPUssF69euYHP6Nhe3rGqPu0LRo4ny+//NL0M7r99tvNde1Aqdk2DZB169mzZ5pgXLN/Y8aMMX2PNKD2Z+VS0u+oBgy6pHPqz7R2APYbPHiw6YOkfYn0O6b1yYhmGN08cgreREbCA/THQ0c/6NlPyh+fOnXqmHkTdBlZPXOaMmWKOaCHgi5Le+DAAXO29MMPP5ggQDuF6dlVykClYsWK5qA+bNgwk/5NecY0atQoqVWrlmk20REUH330kbl9ejRToQGCdmQbMmSI6ZS5detW0zSi5UqzH61atTI/7Jrt0GBBU8F6+9Q0IOnevbupk/44a0pasyOaqvZ34MSlRz+H+rnW5j/tzKsdKzVQ15EaGpimDJC1TG+nnyM/zTzogVw/h4UKFTLXDx48mO7nWkdKPfrooyb41aD2+uuvl4SEBBPwaxOHPq5+n7RJUL+/GkxrJkTLv//+ezMiI7Xhw4ebz712nNaOmRrEaJOgNo9k1JEZuGhB9KuACzuFaecu7ZCV8r903rx5pmNYjhw5fCVKlPA9++yzAffRzpYvvPBCQFn16tV9o0ePzvC5/Z0g/Zt2/tJOaH379vX99ttv6d7ntddeM7ddu3ZtQPnYsWPNfaOionwFChQwr2n79u0Zdur89ddffbfeeqsvX7585j4VKlTwDRw40HQSHTNmjK9o0aK+Q4cOJd9+4cKFvpw5cyY/RsrOlurUqVO+QYMGmfvp7cqWLet7/fXXM3zt8P73yv+5zp49u++KK67wtWzZ0nwmzp49G3Bb/czp96dNmzYB5Vu2bPHdeOON5r76fSxfvrxv8uTJGX539XFefPFF3zXXXGO+p3o/vf/y5ct98fHxvsKFC/vGjRuXfPukpCTfddddZzoUp9fZUi1btszXoEED8/z6XdHHS7kfCDWWEYftnnnmGZM50PQw4AWaibvyyitNtiB1cx1wqaFpA7bRsfXaSU2bXJiaGl6gTRDa9KFNZjotdbt27ZyuEuA4AgnYpl+/fjJ79mzTMc0/PA4IZ9oxUjsUX3XVVWZyNx3eDFzqaNoAAABBY/gnAAAIGoEEAAAIGoEEAAAIGoEEAAAIGoEE4EG6zLQuhuan05Dr6JmstnPnTjNltC4mBcCbCCSALKQHdD2w6qYLoZUpU8ZMk3zixAlbn/fFF180wxUzg4M/gAvBIGggi910001msSddxGzFihVm3QYNJOLi4gJup/szs+pqZujkSQBgBzISQBbTFR+LFCliVni86667zIJrCxcuTG6O0GmXNVOht9NpXo4dOyb333+/WQQqT5480rx5c9m0aVPAY44fP14KFy5sFoLq1auXnD59OmB/6qYNnaFRl2TXlSb1eUqUKGGmMlf+5a51FVfNTDRt2jT5fhoA6QJUuXLlkgoVKqRZBE4XbtP76f7atWub1S8BeBsZCcBhuiKqZh+Urmg6d+5cmT9/fvIqqjfffLMUKFBAPvnkE5NZ+O9//ystWrSQX3/91ZTr7UePHi0vv/yyNGrUSGbNmmVWNNVgJCO6SqSumvrCCy+YVSf3798vP//8c3IwcN1115nl33VlVl1BUunt9Xl0FVkNFjRIuO+++8wy7roipWZVdEVMDXR0WfgdO3bIgAEDsuQ9BOCgkC8DBiBDqVd//Oabb3wxMTFmNUdddVVXgNRVH/2WLFniy5Mnj+/06dMBj3P11Vf7/vvf/5rL9evX9z344IMB++vWrWtWck3veRMSEszKkNOnT0+3jumtvKqKFy/ue+edd9Ks4KrPr7Q+uorriRMnkvfHxcWl+1gAvIOmDSCLffTRR3L55Zeb9H/9+vWlcePGZmEzVbJkSbniiiuSb7thwwaz+FlMTIy5j3/Ts/1t27aZ2+jCaPo4KaW+npLePjEx0WQ1MuvgwYOyZ88e02ySsh5PP/10QD2qV68u0dHRmaoHAG+gaQPIYs2aNTMdK7UjpS5FnbJDpTYTpKR9GYoWLSrLli1L8zj58uULuinlQmk9/M0bdevWDdjnb4Jh2R7g0kQgAWQxDRa0k2Nm1KxZ0yxbratMlipVKt3baOfHNWvWyD333JNcptczUq5cORNMLFmyxIwYSc3fJ+Ls2bPJZdqRs1ixYrJ9+3bTOTQ9lSpVMv0zTp06lRysnK8eALyBpg3AxVq2bGmaB3TExWeffWbmeFi1apU88cQTsn79enMb7dCoIz100w6Y2iHyxx9/zPAxtUll2LBhMnToUJk5c6ZpmtAD/muvvWb26+gQDQQ+/fRT+eOPP8yoEaWjSmJjY82cFPo8mzdvNqM4nn/+ebNfR6BERESY5o8tW7aYzqHPPfdclrxPAJxDIAG4mA6/1AOy9qO49957pXz58tKlSxcTUGiWQHXu3FlGjRplgoNatWrJrl27pE+fPud93JEjR8rgwYPN/TSjoY8RHx9v9mn2Q0d96OgQbXpp3769Kdfsxauvvmomtqpatao0adLEXPYPF9U+Ex9++KEJInRUx4gRI8wQUwDeZmmPS6crAQAAwhMZCQAAEDQCCQAAEDQCCQAAEDQCCQAAEDQCCQAAEDQCCQAAEDQCCQAAEDQCCQAAEDQCCQAAEDQCCQAAEDQCCQAAEDQCCQAAIMH6P4GVIlhW6JMZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.2%}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Dyslexic', 'Dyslexic'], yticklabels=['Non-Dyslexic', 'Dyslexic'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b6932a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02e177f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rjabj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import language_tool_python\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Tesseract path (Windows only)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a57f1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rjabj\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rjabj\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load ResNet18 for feature extraction\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n",
    "\n",
    "# Preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "536f3196",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "def extract_text(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    return pytesseract.image_to_string(image)\n",
    "\n",
    "def grammar_error_count(text):\n",
    "    matches = tool.check(text)\n",
    "    return len(matches)\n",
    "\n",
    "def sentence_features(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    count = len(sentences)\n",
    "    avg_len = np.mean([len(s.split()) for s in sentences]) if sentences else 0\n",
    "    return count, avg_len\n",
    "\n",
    "def line_alignment_variance(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    _, binary = cv2.threshold(img, 180, 255, cv2.THRESH_BINARY_INV)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    x_starts = [cv2.boundingRect(c)[0] for c in contours if cv2.boundingRect(c)[2] > 50]\n",
    "    return np.var(x_starts) if x_starts else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54c02ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_image(image_path):\n",
    "    # CNN Features\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        cnn_features = resnet(img_tensor).cpu().numpy().flatten()\n",
    "    \n",
    "    # Linguistic Features\n",
    "    text = extract_text(image_path)\n",
    "    grammar_errors = grammar_error_count(text)\n",
    "    sentence_count, avg_sentence_length = sentence_features(text)\n",
    "    alignment_var = line_alignment_variance(image_path)\n",
    "    \n",
    "    # Combine features\n",
    "    full_feature_vector = np.concatenate([\n",
    "        cnn_features,\n",
    "        [grammar_errors, sentence_count, avg_sentence_length, alignment_var]\n",
    "    ])\n",
    "    \n",
    "    return full_feature_vector.reshape(1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bca775de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dyslexia(image_path):\n",
    "    features = get_features_from_image(image_path)\n",
    "    prediction = rf_model.predict(features)[0]\n",
    "    proba = rf_model.predict_proba(features)[0]\n",
    "    \n",
    "    label = \"Dyslexic\" if prediction == 1 else \"Non-Dyslexic\"\n",
    "    print(f\"\\n🧠 Prediction: {label}\")\n",
    "    print(f\"Confidence: Dyslexic = {proba[1]:.2%}, Non-Dyslexic = {proba[0]:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "723f708b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Prediction: Dyslexic\n",
      "Confidence: Dyslexic = 87.00%, Non-Dyslexic = 13.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rjabj\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\rjabj\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Replace this path with the actual uploaded image path\n",
    "test_image_path = r\"C:\\Users\\test_image_path.jpg\"\n",
    "\n",
    "predict_dyslexia(test_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e114097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afebf8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c296c0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fbb3ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
